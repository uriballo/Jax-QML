{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T09:01:18.549022Z",
     "start_time": "2025-02-03T09:01:18.545961Z"
    }
   },
   "source": [
    "from flax import nnx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import pennylane as qml\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "jax.config.update(\"jax_disable_jit\", False) # Useful flag for finding out if JIT is causing problems."
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T09:01:18.571059Z",
     "start_time": "2025-02-03T09:01:18.568884Z"
    }
   },
   "source": [
    "N_QUBITS = 10\n",
    "N_LAYERS = 1\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 3e-4"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T09:01:18.578296Z",
     "start_time": "2025-02-03T09:01:18.576124Z"
    }
   },
   "cell_type": "code",
   "source": "dev = qml.device(\"default.qubit\", wires=N_QUBITS)",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T09:01:18.590287Z",
     "start_time": "2025-02-03T09:01:18.588117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@qml.qnode(dev, interface='jax-jit')\n",
    "def circuit(inputs, weights):\n",
    "    features = inputs * jnp.pi / 2\n",
    "\n",
    "    qml.AngleEmbedding(features=features, wires=range(N_QUBITS), rotation=\"X\")\n",
    "    qml.StronglyEntanglingLayers(jnp.pi * jnp.tanh(weights), wires=range(N_QUBITS))\n",
    "\n",
    "    return [qml.expval(qml.PauliY(wires=idx)) for idx in range(N_QUBITS)]\n",
    "\n",
    "vcircuit = jax.vmap(circuit, in_axes=(0, None))"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T09:01:18.635729Z",
     "start_time": "2025-02-03T09:01:18.598590Z"
    }
   },
   "source": [
    "class QuantumCircuit(nnx.Module):\n",
    "  def __init__(self, num_qubits, num_layers, rngs = nnx.Rngs(42)):\n",
    "    key = rngs.params()\n",
    "\n",
    "    weight_shapes = (num_layers, num_qubits, 3)\n",
    "    self.weights = nnx.Param(jax.random.uniform(key, shape=weight_shapes, dtype=jnp.float32))\n",
    "    self.circuit = vcircuit#circuit\n",
    "\n",
    "  def __call__(self, x: jax.Array):\n",
    "    return self.circuit(x, self.weights)"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified MNIST Tutorial from Flax Documentation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T09:01:18.685599Z",
     "start_time": "2025-02-03T09:01:18.644069Z"
    }
   },
   "source": [
    "import tensorflow_datasets as tfds  # TFDS to download MNIST.\n",
    "import tensorflow as tf  # TensorFlow / `tf.data` operations.\n",
    "\n",
    "tf.random.set_seed(0)  # Set the random seed for reproducibility.\n",
    "\n",
    "train_steps = 1200\n",
    "eval_every = 200\n",
    "batch_size = BATCH_SIZE\n",
    "\n",
    "train_ds: tf.data.Dataset = tfds.load('mnist', split='train')\n",
    "test_ds: tf.data.Dataset = tfds.load('mnist', split='test')\n",
    "\n",
    "train_ds = train_ds.map(\n",
    "  lambda sample: {\n",
    "    'image': tf.cast(sample['image'], tf.float32) / 255,\n",
    "    'label': sample['label'],\n",
    "  }\n",
    ")  # normalize train set\n",
    "test_ds = test_ds.map(\n",
    "  lambda sample: {\n",
    "    'image': tf.cast(sample['image'], tf.float32) / 255,\n",
    "    'label': sample['label'],\n",
    "  }\n",
    ")  # Normalize the test set.\n",
    "\n",
    "# Create a shuffled dataset by allocating a buffer size of 1024 to randomly draw elements from.\n",
    "train_ds = train_ds.repeat().shuffle(1024)\n",
    "# Group into batches of `batch_size` and skip incomplete batches, prefetch the next sample to improve latency.\n",
    "train_ds = train_ds.batch(batch_size, drop_remainder=True).take(train_steps).prefetch(1)\n",
    "# Group into batches of `batch_size` and skip incomplete batches, prefetch the next sample to improve latency.\n",
    "test_ds = test_ds.batch(batch_size, drop_remainder=True).prefetch(1)"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technical note on batch size: If the batch size doesn't divide evenly into the dataset size, the model functions will be recompiled every time the last batch is encountered as recompilation is triggered when the input shapes change."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T09:01:19.195294Z",
     "start_time": "2025-02-03T09:01:18.697275Z"
    }
   },
   "source": [
    "from flax import nnx  # The Flax NNX API.\n",
    "from functools import partial\n",
    "\n",
    "class HNN(nnx.Module):\n",
    "  \"\"\"A simple HNN model.\"\"\"\n",
    "\n",
    "  def __init__(self, *, rngs: nnx.Rngs):\n",
    "    self.conv1 = nnx.Conv(1, 32, kernel_size=(3, 3), rngs=rngs)\n",
    "    self.conv2 = nnx.Conv(32, 64, kernel_size=(3, 3), rngs=rngs)\n",
    "    self.avg_pool = partial(nnx.avg_pool, window_shape=(2, 2), strides=(2, 2))\n",
    "    self.linear1 = nnx.Linear(3136, 256, rngs=rngs)\n",
    "    self.linear2 = nnx.Linear(256, 10, rngs=rngs)\n",
    "\n",
    "    self.qcirc1 = QuantumCircuit(N_QUBITS, N_LAYERS)\n",
    "    self.linear3 = nnx.Linear(10, 10, rngs=rngs)\n",
    "    self.linear4 = nnx.Linear(10, 10, rngs=rngs)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    x = self.avg_pool(nnx.relu(self.conv1(x)))\n",
    "    x = self.avg_pool(nnx.relu(self.conv2(x)))\n",
    "    x = x.reshape(x.shape[0], -1)  # flatten\n",
    "    x = nnx.relu(self.linear1(x))\n",
    "    x = nnx.relu(self.linear2(x))\n",
    "    x = jax.nn.standardize(x)\n",
    "    x = nnx.relu(jnp.array(self.qcirc1(x)).reshape(BATCH_SIZE,-1))\n",
    "    x = nnx.relu(self.linear3(x))\n",
    "    x = self.linear4(x)\n",
    "    return x\n",
    "\n",
    "# Instantiate the model.\n",
    "model = HNN(rngs=nnx.Rngs(0))\n",
    "# Visualize it.\n",
    "nnx.display(model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HNN(\n",
      "  conv1=Conv(\n",
      "    kernel_shape=(3, 3, 1, 32),\n",
      "    kernel=Param(\n",
      "      value=Array(shape=(3, 3, 1, 32), dtype=float32)\n",
      "    ),\n",
      "    bias=Param(\n",
      "      value=Array(shape=(32,), dtype=float32)\n",
      "    ),\n",
      "    in_features=1,\n",
      "    out_features=32,\n",
      "    kernel_size=(3, 3),\n",
      "    strides=1,\n",
      "    padding='SAME',\n",
      "    input_dilation=1,\n",
      "    kernel_dilation=1,\n",
      "    feature_group_count=1,\n",
      "    use_bias=True,\n",
      "    mask=None,\n",
      "    dtype=None,\n",
      "    param_dtype=<class 'jax.numpy.float32'>,\n",
      "    precision=None,\n",
      "    kernel_init=<function variance_scaling.<locals>.init at 0x11735cf40>,\n",
      "    bias_init=<function zeros at 0x114efa0c0>,\n",
      "    conv_general_dilated=<function conv_general_dilated at 0x114896de0>\n",
      "  ),\n",
      "  conv2=Conv(\n",
      "    kernel_shape=(3, 3, 32, 64),\n",
      "    kernel=Param(\n",
      "      value=Array(shape=(3, 3, 32, 64), dtype=float32)\n",
      "    ),\n",
      "    bias=Param(\n",
      "      value=Array(shape=(64,), dtype=float32)\n",
      "    ),\n",
      "    in_features=32,\n",
      "    out_features=64,\n",
      "    kernel_size=(3, 3),\n",
      "    strides=1,\n",
      "    padding='SAME',\n",
      "    input_dilation=1,\n",
      "    kernel_dilation=1,\n",
      "    feature_group_count=1,\n",
      "    use_bias=True,\n",
      "    mask=None,\n",
      "    dtype=None,\n",
      "    param_dtype=<class 'jax.numpy.float32'>,\n",
      "    precision=None,\n",
      "    kernel_init=<function variance_scaling.<locals>.init at 0x11735cf40>,\n",
      "    bias_init=<function zeros at 0x114efa0c0>,\n",
      "    conv_general_dilated=<function conv_general_dilated at 0x114896de0>\n",
      "  ),\n",
      "  avg_pool=functools.partial(<function avg_pool at 0x116928a40>, window_shape=(2, 2), strides=(2, 2)),\n",
      "  linear1=Linear(\n",
      "    kernel=Param(\n",
      "      value=Array(shape=(3136, 256), dtype=float32)\n",
      "    ),\n",
      "    bias=Param(\n",
      "      value=Array(shape=(256,), dtype=float32)\n",
      "    ),\n",
      "    in_features=3136,\n",
      "    out_features=256,\n",
      "    use_bias=True,\n",
      "    dtype=None,\n",
      "    param_dtype=<class 'jax.numpy.float32'>,\n",
      "    precision=None,\n",
      "    kernel_init=<function variance_scaling.<locals>.init at 0x11735cf40>,\n",
      "    bias_init=<function zeros at 0x114efa0c0>,\n",
      "    dot_general=<function dot_general at 0x11483f1a0>\n",
      "  ),\n",
      "  linear2=Linear(\n",
      "    kernel=Param(\n",
      "      value=Array(shape=(256, 10), dtype=float32)\n",
      "    ),\n",
      "    bias=Param(\n",
      "      value=Array(shape=(10,), dtype=float32)\n",
      "    ),\n",
      "    in_features=256,\n",
      "    out_features=10,\n",
      "    use_bias=True,\n",
      "    dtype=None,\n",
      "    param_dtype=<class 'jax.numpy.float32'>,\n",
      "    precision=None,\n",
      "    kernel_init=<function variance_scaling.<locals>.init at 0x11735cf40>,\n",
      "    bias_init=<function zeros at 0x114efa0c0>,\n",
      "    dot_general=<function dot_general at 0x11483f1a0>\n",
      "  ),\n",
      "  qcirc1=QuantumCircuit(\n",
      "    weights=Param(\n",
      "      value=Array(shape=(1, 10, 3), dtype=float32)\n",
      "    ),\n",
      "    circuit=<function circuit at 0x42988e980>\n",
      "  ),\n",
      "  linear3=Linear(\n",
      "    kernel=Param(\n",
      "      value=Array(shape=(10, 10), dtype=float32)\n",
      "    ),\n",
      "    bias=Param(\n",
      "      value=Array(shape=(10,), dtype=float32)\n",
      "    ),\n",
      "    in_features=10,\n",
      "    out_features=10,\n",
      "    use_bias=True,\n",
      "    dtype=None,\n",
      "    param_dtype=<class 'jax.numpy.float32'>,\n",
      "    precision=None,\n",
      "    kernel_init=<function variance_scaling.<locals>.init at 0x11735cf40>,\n",
      "    bias_init=<function zeros at 0x114efa0c0>,\n",
      "    dot_general=<function dot_general at 0x11483f1a0>\n",
      "  ),\n",
      "  linear4=Linear(\n",
      "    kernel=Param(\n",
      "      value=Array(shape=(10, 10), dtype=float32)\n",
      "    ),\n",
      "    bias=Param(\n",
      "      value=Array(shape=(10,), dtype=float32)\n",
      "    ),\n",
      "    in_features=10,\n",
      "    out_features=10,\n",
      "    use_bias=True,\n",
      "    dtype=None,\n",
      "    param_dtype=<class 'jax.numpy.float32'>,\n",
      "    precision=None,\n",
      "    kernel_init=<function variance_scaling.<locals>.init at 0x11735cf40>,\n",
      "    bias_init=<function zeros at 0x114efa0c0>,\n",
      "    dot_general=<function dot_general at 0x11483f1a0>\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T09:01:21.301987Z",
     "start_time": "2025-02-03T09:01:19.204737Z"
    }
   },
   "source": [
    "y = model(jnp.ones((BATCH_SIZE, 28, 28, 1)))\n",
    "print(len(y))\n",
    "nested_shape = [len(subtuple) for subtuple in y]\n",
    "print(nested_shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T09:01:21.380378Z",
     "start_time": "2025-02-03T09:01:21.310110Z"
    }
   },
   "source": [
    "import optax\n",
    "\n",
    "learning_rate = LEARNING_RATE\n",
    "momentum = 0.9\n",
    "\n",
    "optimizer = nnx.Optimizer(model, optax.adamw(learning_rate, momentum))\n",
    "metrics = nnx.MultiMetric(\n",
    "  accuracy=nnx.metrics.Accuracy(),\n",
    "  loss=nnx.metrics.Average('loss'),\n",
    ")\n",
    "\n",
    "nnx.display(optimizer)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer(\n",
      "  step=OptState(\n",
      "    value=Array(0, dtype=uint32)\n",
      "  ),\n",
      "  model=HNN(\n",
      "    conv1=Conv(\n",
      "      kernel_shape=(3, 3, 1, 32),\n",
      "      kernel=Param(\n",
      "        value=Array(shape=(3, 3, 1, 32), dtype=float32)\n",
      "      ),\n",
      "      bias=Param(\n",
      "        value=Array(shape=(32,), dtype=float32)\n",
      "      ),\n",
      "      in_features=1,\n",
      "      out_features=32,\n",
      "      kernel_size=(3, 3),\n",
      "      strides=1,\n",
      "      padding='SAME',\n",
      "      input_dilation=1,\n",
      "      kernel_dilation=1,\n",
      "      feature_group_count=1,\n",
      "      use_bias=True,\n",
      "      mask=None,\n",
      "      dtype=None,\n",
      "      param_dtype=<class 'jax.numpy.float32'>,\n",
      "      precision=None,\n",
      "      kernel_init=<function variance_scaling.<locals>.init at 0x11735cf40>,\n",
      "      bias_init=<function zeros at 0x114efa0c0>,\n",
      "      conv_general_dilated=<function conv_general_dilated at 0x114896de0>\n",
      "    ),\n",
      "    conv2=Conv(\n",
      "      kernel_shape=(3, 3, 32, 64),\n",
      "      kernel=Param(\n",
      "        value=Array(shape=(3, 3, 32, 64), dtype=float32)\n",
      "      ),\n",
      "      bias=Param(\n",
      "        value=Array(shape=(64,), dtype=float32)\n",
      "      ),\n",
      "      in_features=32,\n",
      "      out_features=64,\n",
      "      kernel_size=(3, 3),\n",
      "      strides=1,\n",
      "      padding='SAME',\n",
      "      input_dilation=1,\n",
      "      kernel_dilation=1,\n",
      "      feature_group_count=1,\n",
      "      use_bias=True,\n",
      "      mask=None,\n",
      "      dtype=None,\n",
      "      param_dtype=<class 'jax.numpy.float32'>,\n",
      "      precision=None,\n",
      "      kernel_init=<function variance_scaling.<locals>.init at 0x11735cf40>,\n",
      "      bias_init=<function zeros at 0x114efa0c0>,\n",
      "      conv_general_dilated=<function conv_general_dilated at 0x114896de0>\n",
      "    ),\n",
      "    avg_pool=functools.partial(<function avg_pool at 0x116928a40>, window_shape=(2, 2), strides=(2, 2)),\n",
      "    linear1=Linear(\n",
      "      kernel=Param(\n",
      "        value=Array(shape=(3136, 256), dtype=float32)\n",
      "      ),\n",
      "      bias=Param(\n",
      "        value=Array(shape=(256,), dtype=float32)\n",
      "      ),\n",
      "      in_features=3136,\n",
      "      out_features=256,\n",
      "      use_bias=True,\n",
      "      dtype=None,\n",
      "      param_dtype=<class 'jax.numpy.float32'>,\n",
      "      precision=None,\n",
      "      kernel_init=<function variance_scaling.<locals>.init at 0x11735cf40>,\n",
      "      bias_init=<function zeros at 0x114efa0c0>,\n",
      "      dot_general=<function dot_general at 0x11483f1a0>\n",
      "    ),\n",
      "    linear2=Linear(\n",
      "      kernel=Param(\n",
      "        value=Array(shape=(256, 10), dtype=float32)\n",
      "      ),\n",
      "      bias=Param(\n",
      "        value=Array(shape=(10,), dtype=float32)\n",
      "      ),\n",
      "      in_features=256,\n",
      "      out_features=10,\n",
      "      use_bias=True,\n",
      "      dtype=None,\n",
      "      param_dtype=<class 'jax.numpy.float32'>,\n",
      "      precision=None,\n",
      "      kernel_init=<function variance_scaling.<locals>.init at 0x11735cf40>,\n",
      "      bias_init=<function zeros at 0x114efa0c0>,\n",
      "      dot_general=<function dot_general at 0x11483f1a0>\n",
      "    ),\n",
      "    qcirc1=QuantumCircuit(\n",
      "      weights=Param(\n",
      "        value=Array(shape=(1, 10, 3), dtype=float32)\n",
      "      ),\n",
      "      circuit=<function circuit at 0x42988e980>\n",
      "    ),\n",
      "    linear3=Linear(\n",
      "      kernel=Param(\n",
      "        value=Array(shape=(10, 10), dtype=float32)\n",
      "      ),\n",
      "      bias=Param(\n",
      "        value=Array(shape=(10,), dtype=float32)\n",
      "      ),\n",
      "      in_features=10,\n",
      "      out_features=10,\n",
      "      use_bias=True,\n",
      "      dtype=None,\n",
      "      param_dtype=<class 'jax.numpy.float32'>,\n",
      "      precision=None,\n",
      "      kernel_init=<function variance_scaling.<locals>.init at 0x11735cf40>,\n",
      "      bias_init=<function zeros at 0x114efa0c0>,\n",
      "      dot_general=<function dot_general at 0x11483f1a0>\n",
      "    ),\n",
      "    linear4=Linear(\n",
      "      kernel=Param(\n",
      "        value=Array(shape=(10, 10), dtype=float32)\n",
      "      ),\n",
      "      bias=Param(\n",
      "        value=Array(shape=(10,), dtype=float32)\n",
      "      ),\n",
      "      in_features=10,\n",
      "      out_features=10,\n",
      "      use_bias=True,\n",
      "      dtype=None,\n",
      "      param_dtype=<class 'jax.numpy.float32'>,\n",
      "      precision=None,\n",
      "      kernel_init=<function variance_scaling.<locals>.init at 0x11735cf40>,\n",
      "      bias_init=<function zeros at 0x114efa0c0>,\n",
      "      dot_general=<function dot_general at 0x11483f1a0>\n",
      "    )\n",
      "  ),\n",
      "  tx=GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x4415accc0>, update=<function chain.<locals>.update_fn at 0x4415ac680>),\n",
      "  opt_state=(ScaleByAdamState(count=OptArray(\n",
      "    value=Array(0, dtype=int32)\n",
      "  ), mu=State({\n",
      "    'conv1': {\n",
      "      'bias': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(32,), dtype=float32)\n",
      "      ),\n",
      "      'kernel': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(3, 3, 1, 32), dtype=float32)\n",
      "      )\n",
      "    },\n",
      "    'conv2': {\n",
      "      'bias': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(64,), dtype=float32)\n",
      "      ),\n",
      "      'kernel': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(3, 3, 32, 64), dtype=float32)\n",
      "      )\n",
      "    },\n",
      "    'linear1': {\n",
      "      'bias': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(256,), dtype=float32)\n",
      "      ),\n",
      "      'kernel': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(3136, 256), dtype=float32)\n",
      "      )\n",
      "    },\n",
      "    'linear2': {\n",
      "      'bias': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(10,), dtype=float32)\n",
      "      ),\n",
      "      'kernel': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(256, 10), dtype=float32)\n",
      "      )\n",
      "    },\n",
      "    'linear3': {\n",
      "      'bias': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(10,), dtype=float32)\n",
      "      ),\n",
      "      'kernel': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(10, 10), dtype=float32)\n",
      "      )\n",
      "    },\n",
      "    'linear4': {\n",
      "      'bias': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(10,), dtype=float32)\n",
      "      ),\n",
      "      'kernel': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(10, 10), dtype=float32)\n",
      "      )\n",
      "    },\n",
      "    'qcirc1': {\n",
      "      'weights': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(1, 10, 3), dtype=float32)\n",
      "      )\n",
      "    }\n",
      "  }), nu=State({\n",
      "    'conv1': {\n",
      "      'bias': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(32,), dtype=float32)\n",
      "      ),\n",
      "      'kernel': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(3, 3, 1, 32), dtype=float32)\n",
      "      )\n",
      "    },\n",
      "    'conv2': {\n",
      "      'bias': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(64,), dtype=float32)\n",
      "      ),\n",
      "      'kernel': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(3, 3, 32, 64), dtype=float32)\n",
      "      )\n",
      "    },\n",
      "    'linear1': {\n",
      "      'bias': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(256,), dtype=float32)\n",
      "      ),\n",
      "      'kernel': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(3136, 256), dtype=float32)\n",
      "      )\n",
      "    },\n",
      "    'linear2': {\n",
      "      'bias': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(10,), dtype=float32)\n",
      "      ),\n",
      "      'kernel': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(256, 10), dtype=float32)\n",
      "      )\n",
      "    },\n",
      "    'linear3': {\n",
      "      'bias': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(10,), dtype=float32)\n",
      "      ),\n",
      "      'kernel': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(10, 10), dtype=float32)\n",
      "      )\n",
      "    },\n",
      "    'linear4': {\n",
      "      'bias': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(10,), dtype=float32)\n",
      "      ),\n",
      "      'kernel': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(10, 10), dtype=float32)\n",
      "      )\n",
      "    },\n",
      "    'qcirc1': {\n",
      "      'weights': OptVariable(\n",
      "        source_type=<class 'flax.nnx.variablelib.Param'>,\n",
      "        value=Array(shape=(1, 10, 3), dtype=float32)\n",
      "      )\n",
      "    }\n",
      "  })), EmptyState(), EmptyState()),\n",
      "  wrt=<class 'flax.nnx.variablelib.Param'>\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T09:01:21.398123Z",
     "start_time": "2025-02-03T09:01:21.395424Z"
    }
   },
   "source": [
    "@nnx.jit\n",
    "def loss_fn(model: HNN, batch):\n",
    "  logits = model(batch['image'])\n",
    "  loss = optax.softmax_cross_entropy_with_integer_labels(\n",
    "    logits=logits, labels=batch['label']\n",
    "  ).mean()\n",
    "  return loss, logits\n",
    "\n",
    "@nnx.jit\n",
    "def train_step(model: HNN, optimizer: nnx.Optimizer, metrics: nnx.MultiMetric, batch):\n",
    "  \"\"\"Train for a single step.\"\"\"\n",
    "  grad_fn = nnx.value_and_grad(loss_fn, has_aux=True)\n",
    "  (loss, logits), grads = grad_fn(model, batch)\n",
    "  metrics.update(loss=loss, logits=logits, labels=batch['label'])  # In-place updates.\n",
    "  optimizer.update(grads)  # In-place updates.\n",
    "\n",
    "@nnx.jit\n",
    "def eval_step(model: HNN, metrics: nnx.MultiMetric, batch):\n",
    "  loss, logits = loss_fn(model, batch)\n",
    "  metrics.update(loss=loss, logits=logits, labels=batch['label'])  # In-place updates."
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T09:01:21.515678Z",
     "start_time": "2025-02-03T09:01:21.401860Z"
    }
   },
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics_history = {\n",
    "  'train_loss': [],\n",
    "  'train_accuracy': [],\n",
    "  'test_loss': [],\n",
    "  'test_accuracy': [],\n",
    "}\n",
    "\n",
    "for step, batch in enumerate(train_ds.as_numpy_iterator()):\n",
    "  # Run the optimization for one step and make a stateful update to the following:\n",
    "  # - The train state's model parameters\n",
    "  # - The optimizer state\n",
    "  # - The training loss and accuracy batch metrics\n",
    "  train_step(model, optimizer, metrics, batch)\n",
    "\n",
    "  if step > 0 and (step % eval_every == 0 or step == train_steps - 1):  # One training epoch has passed.\n",
    "    # Log the training metrics.\n",
    "    for metric, value in metrics.compute().items():  # Compute the metrics.\n",
    "      metrics_history[f'train_{metric}'].append(value)  # Record the metrics.\n",
    "    print(metrics)\n",
    "    metrics.reset()  # Reset the metrics for the test set.\n",
    "\n",
    "    # Compute the metrics on the test set after each training epoch.\n",
    "    for test_batch in test_ds.as_numpy_iterator():\n",
    "      eval_step(model, metrics, test_batch)\n",
    "\n",
    "    # Log the test metrics.\n",
    "    for metric, value in metrics.compute().items():\n",
    "      metrics_history[f'test_{metric}'].append(value)\n",
    "    print(metrics)\n",
    "    metrics.reset()  # Reset the metrics for the next training epoch.\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    # Plot loss and accuracy in subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax1.set_title('Loss')\n",
    "    ax2.set_title('Accuracy')\n",
    "    for dataset in ('train', 'test'):\n",
    "      ax1.plot(metrics_history[f'{dataset}_loss'], label=f'{dataset}_loss')\n",
    "      ax2.plot(metrics_history[f'{dataset}_accuracy'], label=f'{dataset}_accuracy')\n",
    "    ax1.legend()\n",
    "    ax2.legend()\n",
    "    #plt.show()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 10:01:21.451044: W tensorflow/core/kernels/data/cache_dataset_ops.cc:914] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Argument 'Param(\n  value=Traced<ShapedArray(float32[1,10,3])>with<DynamicJaxprTrace(level=4/0)>\n)' of type <class 'flax.nnx.variablelib.Param'> is not a valid JAX type.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[46], line 16\u001B[0m\n\u001B[1;32m      4\u001B[0m metrics_history \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      5\u001B[0m   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_loss\u001B[39m\u001B[38;5;124m'\u001B[39m: [],\n\u001B[1;32m      6\u001B[0m   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain_accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m: [],\n\u001B[1;32m      7\u001B[0m   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest_loss\u001B[39m\u001B[38;5;124m'\u001B[39m: [],\n\u001B[1;32m      8\u001B[0m   \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest_accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m: [],\n\u001B[1;32m      9\u001B[0m }\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, batch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_ds\u001B[38;5;241m.\u001B[39mas_numpy_iterator()):\n\u001B[1;32m     12\u001B[0m   \u001B[38;5;66;03m# Run the optimization for one step and make a stateful update to the following:\u001B[39;00m\n\u001B[1;32m     13\u001B[0m   \u001B[38;5;66;03m# - The train state's model parameters\u001B[39;00m\n\u001B[1;32m     14\u001B[0m   \u001B[38;5;66;03m# - The optimizer state\u001B[39;00m\n\u001B[1;32m     15\u001B[0m   \u001B[38;5;66;03m# - The training loss and accuracy batch metrics\u001B[39;00m\n\u001B[0;32m---> 16\u001B[0m   \u001B[43mtrain_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetrics\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m step \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m (step \u001B[38;5;241m%\u001B[39m eval_every \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m step \u001B[38;5;241m==\u001B[39m train_steps \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m):  \u001B[38;5;66;03m# One training epoch has passed.\u001B[39;00m\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;66;03m# Log the training metrics.\u001B[39;00m\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m metric, value \u001B[38;5;129;01min\u001B[39;00m metrics\u001B[38;5;241m.\u001B[39mcompute()\u001B[38;5;241m.\u001B[39mitems():  \u001B[38;5;66;03m# Compute the metrics.\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/GitHub/Jax-QML/.venv/lib/python3.12/site-packages/flax/nnx/graph.py:1081\u001B[0m, in \u001B[0;36mUpdateContextManager.__call__.<locals>.update_context_manager_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1078\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f)\n\u001B[1;32m   1079\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mupdate_context_manager_wrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1080\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m-> 1081\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/GitHub/Jax-QML/.venv/lib/python3.12/site-packages/flax/nnx/transforms/compilation.py:345\u001B[0m, in \u001B[0;36mjit.<locals>.jit_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    335\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(fun)\n\u001B[1;32m    336\u001B[0m \u001B[38;5;129m@graph\u001B[39m\u001B[38;5;241m.\u001B[39mupdate_context(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjit\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    337\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mjit_wrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    338\u001B[0m   pure_args, pure_kwargs \u001B[38;5;241m=\u001B[39m extract\u001B[38;5;241m.\u001B[39mto_tree(\n\u001B[1;32m    339\u001B[0m     (args, kwargs),\n\u001B[1;32m    340\u001B[0m     prefix\u001B[38;5;241m=\u001B[39m(in_shardings, kwarg_shardings),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    343\u001B[0m     ctxtag\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjit\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    344\u001B[0m   )\n\u001B[0;32m--> 345\u001B[0m   pure_args_out, pure_kwargs_out, pure_out \u001B[38;5;241m=\u001B[39m \u001B[43mjitted_fn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpure_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpure_kwargs\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    348\u001B[0m   _args_out, _kwargs_out, out \u001B[38;5;241m=\u001B[39m extract\u001B[38;5;241m.\u001B[39mfrom_tree(\n\u001B[1;32m    349\u001B[0m     (pure_args_out, pure_kwargs_out, pure_out), ctxtag\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjit\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    350\u001B[0m   )\n\u001B[1;32m    351\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "    \u001B[0;31m[... skipping hidden 11 frame]\u001B[0m\n",
      "File \u001B[0;32m~/Documents/GitHub/Jax-QML/.venv/lib/python3.12/site-packages/flax/nnx/transforms/compilation.py:112\u001B[0m, in \u001B[0;36mJitFn.__call__\u001B[0;34m(self, *pure_args, **pure_kwargs)\u001B[0m\n\u001B[1;32m    109\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39mpure_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpure_kwargs):\n\u001B[1;32m    110\u001B[0m   args, kwargs \u001B[38;5;241m=\u001B[39m extract\u001B[38;5;241m.\u001B[39mfrom_tree((pure_args, pure_kwargs), ctxtag\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjit\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 112\u001B[0m   out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    114\u001B[0m   args_out, kwargs_out \u001B[38;5;241m=\u001B[39m extract\u001B[38;5;241m.\u001B[39mclear_non_graph_nodes((args, kwargs))\n\u001B[1;32m    115\u001B[0m   pure_args_out, pure_kwargs_out, pure_out \u001B[38;5;241m=\u001B[39m extract\u001B[38;5;241m.\u001B[39mto_tree(\n\u001B[1;32m    116\u001B[0m     (args_out, kwargs_out, out),\n\u001B[1;32m    117\u001B[0m     prefix\u001B[38;5;241m=\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39min_shardings, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwarg_shardings, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mout_shardings),\n\u001B[1;32m    118\u001B[0m     ctxtag\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjit\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    119\u001B[0m     split_fn\u001B[38;5;241m=\u001B[39m_jit_split_fn,\n\u001B[1;32m    120\u001B[0m   )\n",
      "Cell \u001B[0;32mIn[45], line 13\u001B[0m, in \u001B[0;36mtrain_step\u001B[0;34m(model, optimizer, metrics, batch)\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Train for a single step.\"\"\"\u001B[39;00m\n\u001B[1;32m     12\u001B[0m grad_fn \u001B[38;5;241m=\u001B[39m nnx\u001B[38;5;241m.\u001B[39mvalue_and_grad(loss_fn, has_aux\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 13\u001B[0m (loss, logits), grads \u001B[38;5;241m=\u001B[39m \u001B[43mgrad_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m metrics\u001B[38;5;241m.\u001B[39mupdate(loss\u001B[38;5;241m=\u001B[39mloss, logits\u001B[38;5;241m=\u001B[39mlogits, labels\u001B[38;5;241m=\u001B[39mbatch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m])  \u001B[38;5;66;03m# In-place updates.\u001B[39;00m\n\u001B[1;32m     15\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mupdate(grads)\n",
      "File \u001B[0;32m~/Documents/GitHub/Jax-QML/.venv/lib/python3.12/site-packages/flax/nnx/graph.py:1081\u001B[0m, in \u001B[0;36mUpdateContextManager.__call__.<locals>.update_context_manager_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1078\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f)\n\u001B[1;32m   1079\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mupdate_context_manager_wrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1080\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m-> 1081\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/GitHub/Jax-QML/.venv/lib/python3.12/site-packages/flax/nnx/transforms/autodiff.py:164\u001B[0m, in \u001B[0;36m_grad_general.<locals>.grad_wrapper\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m    159\u001B[0m pure_args \u001B[38;5;241m=\u001B[39m extract\u001B[38;5;241m.\u001B[39mto_tree(\n\u001B[1;32m    160\u001B[0m   args, prefix\u001B[38;5;241m=\u001B[39marg_filters, split_fn\u001B[38;5;241m=\u001B[39m_grad_split_fn, ctxtag\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgrad\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    161\u001B[0m )\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m extract\u001B[38;5;241m.\u001B[39mbroadcast_state(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgrad\u001B[39m\u001B[38;5;124m'\u001B[39m, nondiff_states):\n\u001B[0;32m--> 164\u001B[0m   fn_out \u001B[38;5;241m=\u001B[39m \u001B[43mgradded_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpure_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mprocess_grads\u001B[39m(grads):\n\u001B[1;32m    167\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m jax\u001B[38;5;241m.\u001B[39mtree\u001B[38;5;241m.\u001B[39mmap(\n\u001B[1;32m    168\u001B[0m     \u001B[38;5;28;01mlambda\u001B[39;00m x: x\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, extract\u001B[38;5;241m.\u001B[39mNodeStates) \u001B[38;5;28;01melse\u001B[39;00m x,\n\u001B[1;32m    169\u001B[0m     grads,\n\u001B[1;32m    170\u001B[0m     is_leaf\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;28misinstance\u001B[39m(x, extract\u001B[38;5;241m.\u001B[39mNodeStates),\n\u001B[1;32m    171\u001B[0m   )\n",
      "    \u001B[0;31m[... skipping hidden 8 frame]\u001B[0m\n",
      "File \u001B[0;32m~/Documents/GitHub/Jax-QML/.venv/lib/python3.12/site-packages/flax/nnx/transforms/autodiff.py:86\u001B[0m, in \u001B[0;36mGradFn.__call__\u001B[0;34m(self, *pure_args)\u001B[0m\n\u001B[1;32m     82\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ctx\u001B[38;5;241m.\u001B[39mmerge(value\u001B[38;5;241m.\u001B[39mgraphdef, value\u001B[38;5;241m.\u001B[39mstate, nondiff)\n\u001B[1;32m     84\u001B[0m args \u001B[38;5;241m=\u001B[39m extract\u001B[38;5;241m.\u001B[39mfrom_tree(pure_args, merge_fn\u001B[38;5;241m=\u001B[39m_grad_merge_fn, ctxtag\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgrad\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 86\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     88\u001B[0m args_out \u001B[38;5;241m=\u001B[39m extract\u001B[38;5;241m.\u001B[39mclear_non_graph_nodes(args)\n\u001B[1;32m     89\u001B[0m pure_args_out, pure_out \u001B[38;5;241m=\u001B[39m extract\u001B[38;5;241m.\u001B[39mto_tree((args_out, out), ctxtag\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgrad\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/GitHub/Jax-QML/.venv/lib/python3.12/site-packages/flax/nnx/graph.py:1081\u001B[0m, in \u001B[0;36mUpdateContextManager.__call__.<locals>.update_context_manager_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1078\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(f)\n\u001B[1;32m   1079\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mupdate_context_manager_wrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1080\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m-> 1081\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/GitHub/Jax-QML/.venv/lib/python3.12/site-packages/flax/nnx/transforms/compilation.py:345\u001B[0m, in \u001B[0;36mjit.<locals>.jit_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    335\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(fun)\n\u001B[1;32m    336\u001B[0m \u001B[38;5;129m@graph\u001B[39m\u001B[38;5;241m.\u001B[39mupdate_context(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjit\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    337\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mjit_wrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    338\u001B[0m   pure_args, pure_kwargs \u001B[38;5;241m=\u001B[39m extract\u001B[38;5;241m.\u001B[39mto_tree(\n\u001B[1;32m    339\u001B[0m     (args, kwargs),\n\u001B[1;32m    340\u001B[0m     prefix\u001B[38;5;241m=\u001B[39m(in_shardings, kwarg_shardings),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    343\u001B[0m     ctxtag\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjit\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    344\u001B[0m   )\n\u001B[0;32m--> 345\u001B[0m   pure_args_out, pure_kwargs_out, pure_out \u001B[38;5;241m=\u001B[39m \u001B[43mjitted_fn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpure_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpure_kwargs\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    348\u001B[0m   _args_out, _kwargs_out, out \u001B[38;5;241m=\u001B[39m extract\u001B[38;5;241m.\u001B[39mfrom_tree(\n\u001B[1;32m    349\u001B[0m     (pure_args_out, pure_kwargs_out, pure_out), ctxtag\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjit\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    350\u001B[0m   )\n\u001B[1;32m    351\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "    \u001B[0;31m[... skipping hidden 11 frame]\u001B[0m\n",
      "File \u001B[0;32m~/Documents/GitHub/Jax-QML/.venv/lib/python3.12/site-packages/flax/nnx/transforms/compilation.py:112\u001B[0m, in \u001B[0;36mJitFn.__call__\u001B[0;34m(self, *pure_args, **pure_kwargs)\u001B[0m\n\u001B[1;32m    109\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39mpure_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpure_kwargs):\n\u001B[1;32m    110\u001B[0m   args, kwargs \u001B[38;5;241m=\u001B[39m extract\u001B[38;5;241m.\u001B[39mfrom_tree((pure_args, pure_kwargs), ctxtag\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjit\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 112\u001B[0m   out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    114\u001B[0m   args_out, kwargs_out \u001B[38;5;241m=\u001B[39m extract\u001B[38;5;241m.\u001B[39mclear_non_graph_nodes((args, kwargs))\n\u001B[1;32m    115\u001B[0m   pure_args_out, pure_kwargs_out, pure_out \u001B[38;5;241m=\u001B[39m extract\u001B[38;5;241m.\u001B[39mto_tree(\n\u001B[1;32m    116\u001B[0m     (args_out, kwargs_out, out),\n\u001B[1;32m    117\u001B[0m     prefix\u001B[38;5;241m=\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39min_shardings, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwarg_shardings, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mout_shardings),\n\u001B[1;32m    118\u001B[0m     ctxtag\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mjit\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m    119\u001B[0m     split_fn\u001B[38;5;241m=\u001B[39m_jit_split_fn,\n\u001B[1;32m    120\u001B[0m   )\n",
      "Cell \u001B[0;32mIn[45], line 3\u001B[0m, in \u001B[0;36mloss_fn\u001B[0;34m(model, batch)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;129m@nnx\u001B[39m\u001B[38;5;241m.\u001B[39mjit\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mloss_fn\u001B[39m(model: HNN, batch):\n\u001B[0;32m----> 3\u001B[0m   logits \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mimage\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m   loss \u001B[38;5;241m=\u001B[39m optax\u001B[38;5;241m.\u001B[39msoftmax_cross_entropy_with_integer_labels(\n\u001B[1;32m      5\u001B[0m     logits\u001B[38;5;241m=\u001B[39mlogits, labels\u001B[38;5;241m=\u001B[39mbatch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      6\u001B[0m   )\u001B[38;5;241m.\u001B[39mmean()\n\u001B[1;32m      7\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m loss, logits\n",
      "Cell \u001B[0;32mIn[42], line 25\u001B[0m, in \u001B[0;36mHNN.__call__\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     23\u001B[0m x \u001B[38;5;241m=\u001B[39m nnx\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear2(x))\n\u001B[1;32m     24\u001B[0m x \u001B[38;5;241m=\u001B[39m jax\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39mstandardize(x)\n\u001B[0;32m---> 25\u001B[0m x \u001B[38;5;241m=\u001B[39m nnx\u001B[38;5;241m.\u001B[39mrelu(jnp\u001B[38;5;241m.\u001B[39marray(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mqcirc1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\u001B[38;5;241m.\u001B[39mreshape(BATCH_SIZE,\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m     26\u001B[0m x \u001B[38;5;241m=\u001B[39m nnx\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear3(x))\n\u001B[1;32m     27\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear4(x)\n",
      "Cell \u001B[0;32mIn[40], line 10\u001B[0m, in \u001B[0;36mQuantumCircuit.__call__\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: jax\u001B[38;5;241m.\u001B[39mArray):\n\u001B[0;32m---> 10\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcircuit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweights\u001B[49m\u001B[43m)\u001B[49m\n",
      "    \u001B[0;31m[... skipping hidden 3 frame]\u001B[0m\n",
      "File \u001B[0;32m~/Documents/GitHub/Jax-QML/.venv/lib/python3.12/site-packages/pennylane/workflow/qnode.py:905\u001B[0m, in \u001B[0;36mQNode.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    903\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m qml\u001B[38;5;241m.\u001B[39mcapture\u001B[38;5;241m.\u001B[39menabled():\n\u001B[1;32m    904\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m capture_qnode(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 905\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_impl_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/GitHub/Jax-QML/.venv/lib/python3.12/site-packages/pennylane/workflow/qnode.py:868\u001B[0m, in \u001B[0;36mQNode._impl_call\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    865\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_impl_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m qml\u001B[38;5;241m.\u001B[39mtyping\u001B[38;5;241m.\u001B[39mResult:\n\u001B[1;32m    866\u001B[0m \n\u001B[1;32m    867\u001B[0m     \u001B[38;5;66;03m# construct the tape\u001B[39;00m\n\u001B[0;32m--> 868\u001B[0m     tape \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstruct\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minterface \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    871\u001B[0m         interface \u001B[38;5;241m=\u001B[39m qml\u001B[38;5;241m.\u001B[39mmath\u001B[38;5;241m.\u001B[39mget_interface(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlist\u001B[39m(kwargs\u001B[38;5;241m.\u001B[39mvalues()))\n",
      "File \u001B[0;32m~/Documents/GitHub/Jax-QML/.venv/lib/python3.12/site-packages/pennylane/logging/decorators.py:61\u001B[0m, in \u001B[0;36mlog_string_debug_func.<locals>.wrapper_entry\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     54\u001B[0m     s_caller \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m::L\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\n\u001B[1;32m     55\u001B[0m         [\u001B[38;5;28mstr\u001B[39m(i) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39mgetouterframes(inspect\u001B[38;5;241m.\u001B[39mcurrentframe(), \u001B[38;5;241m2\u001B[39m)[\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m1\u001B[39m:\u001B[38;5;241m3\u001B[39m]]\n\u001B[1;32m     56\u001B[0m     )\n\u001B[1;32m     57\u001B[0m     lgr\u001B[38;5;241m.\u001B[39mdebug(\n\u001B[1;32m     58\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCalling \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mf_string\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m from \u001B[39m\u001B[38;5;132;01m{\u001B[39;00ms_caller\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     59\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m_debug_log_kwargs,\n\u001B[1;32m     60\u001B[0m     )\n\u001B[0;32m---> 61\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/GitHub/Jax-QML/.venv/lib/python3.12/site-packages/pennylane/workflow/qnode.py:854\u001B[0m, in \u001B[0;36mQNode.construct\u001B[0;34m(self, args, kwargs)\u001B[0m\n\u001B[1;32m    852\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m pldb_device_manager(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice):\n\u001B[1;32m    853\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m qml\u001B[38;5;241m.\u001B[39mqueuing\u001B[38;5;241m.\u001B[39mAnnotatedQueue() \u001B[38;5;28;01mas\u001B[39;00m q:\n\u001B[0;32m--> 854\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_qfunc_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    856\u001B[0m tape \u001B[38;5;241m=\u001B[39m QuantumScript\u001B[38;5;241m.\u001B[39mfrom_queue(q, shots)\n\u001B[1;32m    858\u001B[0m params \u001B[38;5;241m=\u001B[39m tape\u001B[38;5;241m.\u001B[39mget_parameters(trainable_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Cell \u001B[0;32mIn[39], line 6\u001B[0m, in \u001B[0;36mcircuit\u001B[0;34m(inputs, weights)\u001B[0m\n\u001B[1;32m      3\u001B[0m features \u001B[38;5;241m=\u001B[39m inputs \u001B[38;5;241m*\u001B[39m jnp\u001B[38;5;241m.\u001B[39mpi \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m      5\u001B[0m qml\u001B[38;5;241m.\u001B[39mAngleEmbedding(features\u001B[38;5;241m=\u001B[39mfeatures, wires\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mrange\u001B[39m(N_QUBITS), rotation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 6\u001B[0m qml\u001B[38;5;241m.\u001B[39mStronglyEntanglingLayers(jnp\u001B[38;5;241m.\u001B[39mpi \u001B[38;5;241m*\u001B[39m \u001B[43mjnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtanh\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweights\u001B[49m\u001B[43m)\u001B[49m, wires\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mrange\u001B[39m(N_QUBITS))\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m [qml\u001B[38;5;241m.\u001B[39mexpval(qml\u001B[38;5;241m.\u001B[39mPauliY(wires\u001B[38;5;241m=\u001B[39midx)) \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(N_QUBITS)]\n",
      "    \u001B[0;31m[... skipping hidden 3 frame]\u001B[0m\n",
      "File \u001B[0;32m~/Documents/GitHub/Jax-QML/.venv/lib/python3.12/site-packages/jax/_src/dispatch.py:288\u001B[0m, in \u001B[0;36mcheck_arg\u001B[0;34m(arg)\u001B[0m\n\u001B[1;32m    286\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mcheck_arg\u001B[39m(arg: Any):\n\u001B[1;32m    287\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28misinstance\u001B[39m(arg, core\u001B[38;5;241m.\u001B[39mTracer) \u001B[38;5;129;01mor\u001B[39;00m core\u001B[38;5;241m.\u001B[39mvalid_jaxtype(arg)):\n\u001B[0;32m--> 288\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mArgument \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00marg\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m of type \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(arg)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not a valid \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    289\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJAX type.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: Argument 'Param(\n  value=Traced<ShapedArray(float32[1,10,3])>with<DynamicJaxprTrace(level=4/0)>\n)' of type <class 'flax.nnx.variablelib.Param'> is not a valid JAX type."
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T09:01:21.517747Z",
     "start_time": "2025-02-03T08:59:56.075685Z"
    }
   },
   "source": [
    "model.eval() # Switch to evaluation mode.\n",
    "\n",
    "@nnx.jit\n",
    "def pred_step(model: HNN, batch):\n",
    "  logits = model(batch['image'])\n",
    "  return logits.argmax(axis=1)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T09:01:21.517980Z",
     "start_time": "2025-02-03T08:59:56.086472Z"
    }
   },
   "source": [
    "test_batch = test_ds.as_numpy_iterator().next()\n",
    "pred = pred_step(model, test_batch)\n",
    "\n",
    "fig, axs = plt.subplots(5, 5, figsize=(12, 12))\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "  ax.imshow(test_batch['image'][i, ..., 0], cmap='gray')\n",
    "  ax.set_title(f'label={pred[i]}')\n",
    "  ax.axis('off')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1200 with 25 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
